{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4d684172-4b94-42cf-bda2-e11952420d86",
      "metadata": {
        "id": "4d684172-4b94-42cf-bda2-e11952420d86"
      },
      "source": [
        "# Homework 10\n",
        "#### Course Notes\n",
        "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
        "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
        "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"httr\")\n",
        "install.packages(\"tokenizers\")\n",
        "library(httr)\n",
        "library(tokenizers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H-xwBcdgNGU",
        "outputId": "a648ed8b-17dd-4af8-afde-e915cca9e685"
      },
      "id": "9H-xwBcdgNGU",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "Installing package into ‘/usr/local/lib/R/site-library’\n",
            "(as ‘lib’ is unspecified)\n",
            "\n",
            "also installing the dependency ‘SnowballC’\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d839a5ba-62f4-4699-baea-018afda70786",
      "metadata": {
        "id": "d839a5ba-62f4-4699-baea-018afda70786"
      },
      "source": [
        "## Question 1\n",
        "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
      "metadata": {
        "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49"
      },
      "source": [
        "#### a) Make a function to tokenize the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize_text <- function(text) {\n",
        "    tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "jQLEse4Mfg9e"
      },
      "id": "jQLEse4Mfg9e",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "86145513-294b-4894-a02c-8ae60e2c616e",
      "metadata": {
        "id": "86145513-294b-4894-a02c-8ae60e2c616e"
      },
      "source": [
        "#### b) Make a function generate keys for ngrams."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key_from <- function(ngram, sep = \"\\x1f\") {\n",
        "    paste(ngram, collapse=sep)\n",
        "}"
      ],
      "metadata": {
        "id": "Lfb4WZSjfnDW"
      },
      "id": "Lfb4WZSjfnDW",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "52988c2c-b230-467f-b519-72bc85b93b43",
      "metadata": {
        "id": "52988c2c-b230-467f-b519-72bc85b93b43"
      },
      "source": [
        "#### c) Make a function to build an ngram table."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
        "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
        "    tbl <- new.env(parent = emptyenv())\n",
        "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
        "        ngram <- tokens[i:(i + n - 2L)]\n",
        "        next_word <- tokens[i + n - 1L]\n",
        "        key <- paste(ngram, collapse = sep)\n",
        "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "        if (next_word %in% names(counts)) {\n",
        "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
        "        } else {\n",
        "            counts[[next_word]] <- 1L\n",
        "        }\n",
        "        tbl[[key]] <- counts\n",
        "    }\n",
        "    tbl\n",
        "}"
      ],
      "metadata": {
        "id": "NrocVoBnf9nq"
      },
      "id": "NrocVoBnf9nq",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1ca6db37-abce-4705-9784-e1b898174f00",
      "metadata": {
        "id": "1ca6db37-abce-4705-9784-e1b898174f00"
      },
      "source": [
        "#### d) Function to digest the text."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_text <- function(text, n) {\n",
        "    tokens <- tokenize_text(text)\n",
        "    build_ngram_table(tokens, n)\n",
        "}"
      ],
      "metadata": {
        "id": "aLcuP4lOf_0U"
      },
      "id": "aLcuP4lOf_0U",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
      "metadata": {
        "id": "53fff313-0f13-479b-94df-7588c19fdd3d"
      },
      "source": [
        "#### e) Function to digest the url."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "digest_url <- function(url, n) {\n",
        "    res <- httr::GET(url)\n",
        "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
        "    digest_text(txt,n)\n",
        "}"
      ],
      "metadata": {
        "id": "hot0LtYqgB8C"
      },
      "id": "hot0LtYqgB8C",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
      "metadata": {
        "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a"
      },
      "source": [
        "#### f) Function that gives random start."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_start <- function(tbl, sep = \"\\x1f\") {\n",
        "    keys <- ls(envir = tbl, all.names=TRUE)\n",
        "    if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
        "    picked <- sample(keys, 1)\n",
        "    strsplit(picked, sep, fixed=TRUE)[[1]]\n",
        "}"
      ],
      "metadata": {
        "id": "sEpRLz0KgEHV"
      },
      "id": "sEpRLz0KgEHV",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
      "metadata": {
        "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f"
      },
      "source": [
        "#### g) Function to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
        "    key <- paste(ngram, collapse = sep)\n",
        "    counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
        "    if (length(counts) == 0) return(NA_character_)\n",
        "    sample(names(counts), size=1, prob=as.numeric(counts))\n",
        "}"
      ],
      "metadata": {
        "id": "-xwBm1Q6gGFX"
      },
      "id": "-xwBm1Q6gGFX",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "347f4002-4932-42c4-a4af-8689293a5857",
      "metadata": {
        "id": "347f4002-4932-42c4-a4af-8689293a5857"
      },
      "source": [
        "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
        "    force(tbl); n <- as.integer(n); force(sep)\n",
        "    function(start_words = NULL, length = 10L) {\n",
        "        if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
        "            start_words <- random_start(tbl, sep=sep)\n",
        "        }\n",
        "        word_sequence <- start_words\n",
        "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
        "            ngram <- tail(word_sequence, n - 1L)\n",
        "            next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
        "            if (is.na(next_word)) break\n",
        "            word_sequence <- c(word_sequence, next_word)\n",
        "        }\n",
        "        paste(word_sequence, collapse= \" \")\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "itEur-JTgIbt"
      },
      "id": "itEur-JTgIbt",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
      "metadata": {
        "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554"
      },
      "source": [
        "## Question 2\n",
        "#### For this question, set `seed=2025`.\n",
        "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2025)\n",
        "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
        "tbl3 <- digest_url(url, n=3)\n",
        "gen3 <- make_ngram_generator(tbl3, n=3)\n",
        "\n",
        "print(gen3(start_words=c(\"the\",\"king\"),length=15))\n",
        "print(gen3(length=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze0ZYMqRgL0s",
        "outputId": "041d70cf-7322-4164-b41a-b330fba287a3"
      },
      "id": "ze0ZYMqRgL0s",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"the king has forbidden me to marry another husband am not i shall ride upon\"\n",
            "[1] \"song was over the lake and herself into her little daughter’s hand and was about\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
      "metadata": {
        "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc"
      },
      "source": [
        "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
        "#### i) Using n=3, with the start word(s) \"the king\", with length=15.\n",
        "#### ii) Using n=3, with no start word, with length=15."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(2025)\n",
        "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
        "tbl3 <- digest_url(url, n=3)\n",
        "gen3 <- make_ngram_generator(tbl3, n=3)\n",
        "\n",
        "print(gen3(start_words=c(\"the\", \"king\"),length=15))\n",
        "print(gen3(length=15))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieOoBl84jEyX",
        "outputId": "bc099683-3d7f-4961-9dc3-adb6509d6b14"
      },
      "id": "ieOoBl84jEyX",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] \"the king he added to the entire exclusion of the swords were made prisoners the\"\n",
            "[1] \"king was campaigning in france denmark germany switzerland and livonia figures 5 and the sword\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
      "metadata": {
        "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc"
      },
      "source": [
        "#### c) Explain in 1-2 sentences the difference in content generated from each source."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The content generated from Grimm's Fairy Tales is largely like a fairytale. In contrast, the second source is more historical and has elements of war and conques with the use of weapons, prisoners, countries.**"
      ],
      "metadata": {
        "id": "Na-8wEigjTON"
      },
      "id": "Na-8wEigjTON"
    },
    {
      "cell_type": "markdown",
      "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
      "metadata": {
        "id": "56e45972-f441-4d07-9073-fcddd6146cbd"
      },
      "source": [
        "## Question 3\n",
        "#### a) What is a language learning model?\n",
        "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)A lanuguage model is a type of machine learning model that predicts the probability of a sequence of words to understand and generate human language.**\n",
        "\n",
        "**b)You can run a language model locally by using Docker or Ollama, which allow you to download the model and run it entirely offline.**"
      ],
      "metadata": {
        "id": "nJ-grRwojVVN"
      },
      "id": "nJ-grRwojVVN"
    },
    {
      "cell_type": "markdown",
      "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
      "metadata": {
        "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8"
      },
      "source": [
        "## Question 4\n",
        "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
        "| Term | Meaning |  \n",
        "|------|---------|\n",
        "| **Shell** | The program that interprets and runs the command. |\n",
        "| **Terminal emulator** | The application window that hosts the shell and displays the text that you type along with the shell's response. |\n",
        "| **Process** | It is a running program. |\n",
        "| **Signal** | A message that is set to a process to tell it to do something. Signals are not used here but the mkdir could recieve them. |\n",
        "| **Standard input** | A stream a process can read from. mkdir does not read from the standard input. |\n",
        "| **Standard output** | This is where a process writes text output and typically mkdir writes nothing unless there is an error. |\n",
        "| **Command line argument** | This is extra text that is passed into a program. in mkdir project the project portion is the argument that tells mkdir which directory to make. |\n",
        "| **The environment** | It is the set of variables avaialbe to the process. The shell uses the environment to find the mkdir program and run it. |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
      "metadata": {
        "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2"
      },
      "source": [
        "## Question 5\n",
        "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
        "#### a) What are the programs?\n",
        "#### b) Explain what this command is doing, part by part."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)The programs are find xargs and grep.**\n",
        "\n",
        "**b)find . -iname \"*.R\" is searching the current directory (.), and the subdirectories for files whose names end with (.R) irrespective of the case. The pipe (|) sends the list of matchign filenames from find into the next program. xargs grep read_csv takes the filenames it has recieved from find and then passes them as arguements to grep read_csv which then searches inside each file for read_csv.**"
      ],
      "metadata": {
        "id": "MD1BmpDyqe-Q"
      },
      "id": "MD1BmpDyqe-Q"
    },
    {
      "cell_type": "markdown",
      "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
      "metadata": {
        "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095"
      },
      "source": [
        "## Question 6\n",
        "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions.\n",
        "#### a) Show the response when you run `docker run hello-world`.\n",
        "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
        "#### c) How do you log in to the RStudio server?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**a)**\n",
        "Hello from Docker!\n",
        "This message shows that your installation appears to be working correctly.\n",
        "\n",
        "To generate this message, Docker took the following steps:\n",
        " 1. The Docker client contacted the Docker daemon.\n",
        " 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n",
        "    (amd64)\n",
        " 3. The Docker daemon created a new container from that image which runs the\n",
        "    executable that produces the output you are currently reading.\n",
        " 4. The Docker daemon streamed that output to the Docker client, which sent it\n",
        "    to your terminal.\n",
        "\n",
        "To try something more ambitious, you can run an Ubuntu container with:\n",
        " $ docker run -it ubuntu bash\n",
        "\n",
        "Share images, automate workflows, and more with a free Docker ID:\n",
        " https://hub.docker.com/\n",
        "\n",
        "For more examples and ideas, visit:\n",
        " https://docs.docker.com/get-started/\n",
        "\n",
        "\n",
        "**b)**\n",
        "input: docker run -d -p 8787:8787 -e PASSWORD=mypassword -v ~/Desktop/rprojects:/home/rstudio/projects rocker/rstudio\n",
        "\n",
        "output: 2e2044093ea6a6b1cb28df51908a0a5dc1af31985539a143c1ded69b7a7c5b18\n",
        "\n",
        "**c)**\n",
        "go to localhost:8787, type studio as the username and the password is whatever we set our password to in part b.\n"
      ],
      "metadata": {
        "id": "Gb3saNsbBXKg"
      },
      "id": "Gb3saNsbBXKg"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.3.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}